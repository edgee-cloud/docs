---
title: Why Edgee?
description: The technology behind the fastest, most secure AI Gateway
icon: sparkles
---

Edgee isn't just another proxy. It's an **edge-native AI Gateway that cuts LLM costs by up to 50%** through intelligent token compression. Combined with edge computing, intelligent routing, and zero-trust security, it's purpose-built for production AI workloads at scale.

## Token Compression

When enabled, token compression runs at the edge before your request reaches LLM providers. This can reduce input tokens by up to 50% for common workloads like RAG pipelines, long document analysis, and multi-turn conversations.

<Columns cols={3}>
  <Card icon="dollar-sign" iconType="duotone" color="#8924A6">
    **Up to 50%** token reduction
  </Card>
  <Card icon="clock" iconType="duotone" color="#8924A6">
    **Lower latency** with smaller payloads
  </Card>
  <Card icon="chart-line" iconType="duotone" color="#8924A6">
    **Real-time** savings tracking
  </Card>
</Columns>

### How It Works

Token compression analyzes your prompt structure to:
- Remove redundant context without losing semantic meaning
- Optimize RAG document formatting for better compression ratios
- Preserve critical instructions and few-shot examples
- Maintain output quality while reducing input costs

<Note>
  Compression is most effective for prompts with repeated context (RAG), long system instructions, or verbose multi-turn histories. Simple queries may see minimal compression.
</Note>

## Edge-First Architecture

Traditional AI gateways route all traffic through centralized servers. Edgee processes requests at the edge, closest to your application or user.

<Columns cols={3}>
  <Card icon="zap" iconType="duotone" color="#8924A6">
    **< 10ms** processing overhead
  </Card>
  <Card icon="globe" iconType="duotone" color="#8924A6">
    **100+** edge locations
  </Card>
  <Card icon="shield-check" iconType="duotone" color="#8924A6">
    **Privacy** controls built-in
  </Card>
</Columns>

### How It Works

<Steps>
  <Step title="Request hits nearest edge node">
    Your request arrives at one of 100+ global PoPs within milliseconds.
  </Step>
  <Step title="Token compression">
    Prompts are compressed by up to 50% while preserving semantic meaning.
  </Step>
  <Step title="Intelligent routing">
    Our engine selects the optimal model based on cost, performance, or your custom rules.
  </Step>
  <Step title="Automatic failover">
    If a provider fails, we instantly retry with your backup models.
  </Step>
  <Step title="Response streams back">
    Results stream directly to your app with full observability and cost tracking logged.
  </Step>
</Steps>


### Global Network

Powered by **Fastly** and **AWS**, our network spans six continents:

<img
  className="block dark:hidden"
  src="/images/map-light.png"
  alt="Edge network map"
/>
<img
  className="hidden dark:block"
  src="/images/map-dark.png"
  alt="Edge network map"
/>

<Note>
  Requests are automatically routed to the nearest PoP via Anycast. No configuration needed.
</Note>


### One Key, All Models

With a single Edgee API key, you get instant access to every supported model; OpenAI, Anthropic, Google, Mistral, and more. No need to manage multiple provider accounts or juggle API keys:

<CodeGroup dropdown>
  
```typescript
const edgee = new Edgee();

// Access any model with the same key
await edgee.send({ model: 'gpt-4o', input: 'Hello, world!' });
await edgee.send({ model: 'claude-sonnet-4.5', input: 'Hello, world!' });
await edgee.send({ model: 'gemini-3-pro', input: 'Hello, world!' });
```

```python
from edgee import Edgee

edgee = Edgee()

# Access any model with the same key
edgee.send(model='gpt-4o', input='Hello, world!')
edgee.send(model='claude-sonnet-4.5', input='Hello, world!')
edgee.send(model='gemini-3-pro', input='Hello, world!')
```

```rust
use edgee::Edgee;

let client = Edgee::from_env()?;

// Access any model with the same key
client.send("gpt-4o", "Hello, world!").await?;
client.send("claude-sonnet-4.5", "Hello, world!").await?;
client.send("gemini-3-pro", "Hello, world!").await?;
```

```go
import "github.com/edgee-cloud/go-sdk/edgee"

client, _ := edgee.NewClient(nil)

// Access any model with the same key
client.Send("gpt-4o", "Hello, world!")
client.Send("claude-sonnet-4.5", "Hello, world!")
client.Send("gemini-3-pro", "Hello, world!")
```

</CodeGroup>


### Bring Your Own Keys

Need more control? Use your existing provider API keys alongside Edgee. This gives you direct billing relationships, access to custom fine-tuned models, and the ability to use provider-specific features.

You can mix both approachesâ€”use Edgee's unified access for some providers and your own keys for others.

<Frame caption="Bring Your Own Keys">
<img
  className="block dark:hidden"
  src="/images/byok-light.png"
  alt="BYOK"
/>
<img
  className="hidden dark:block"
  src="/images/byok-dark.png"
  alt="BYOK"
/>
</Frame>