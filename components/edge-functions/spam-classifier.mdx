---
title: Spam Classifier
description: High-performance spam detection component using machine learning at the edge for real-time content classification.
---

import EdgeeSdk from '/snippets/edgee-sdk.mdx';

<EdgeeSdk />

Find it on GitHub: [<Icon icon="github" iconType="solid" /> /edgee-cloud/spam-classifier-component](https://github.com/edgee-cloud/spam-classifier-component)

The Spam Classifier component is a high-performance machine learning edge function that provides real-time spam detection using a Naive Bayesian classifier.
This WASM-based component runs at the edge, offering fast and accurate content classification without requiring external services or additional backend infrastructure.

## What is the Spam Classifier Component?

The Spam Classifier component is a security-focused edge function that:
- Uses Naive Bayes algorithms with Finite State Transducers (FST) for optimal performance
- Provides real-time text classification with confidence scores
- Supports multi-language content analysis
- Runs entirely at the edge as a WASM component
- Returns detailed classification results with spam probabilities
- Requires no external API calls or backend dependencies

## Getting Started

<Steps>
<Step title="Access Component Library">
  Open the Edgee console and navigate to your project's Components section.
</Step>

<Step title="Add Spam Classifier Component">
  Select "Add a component" and choose `edgee/spam-classifier` from the list of available components.
</Step>

<Step title="Configure Component Settings">
  Set up the component configuration:
  - **Endpoint path**: Configure the URL path (e.g., `/classify` or `/spam-check`)
  - **Spam classification threshold** (optional): Set the probability threshold (default: 0.80 works well for most cases)  
  - **Laplace smoothing factor** (optional): Configure Laplace smoothing (default: 1.0 provides good balance)
</Step>

<Step title="Deploy Component">
  Click Save to deploy the component to your edge infrastructure.
  
  <Check>
  The component will be available at your configured endpoint within minutes.
  </Check>
</Step>
</Steps>

## Configuration

When adding the Spam Classifier component to your project through the Edgee console, you can customize its behavior with these settings:

<ParamField path="path" type="string" default="/classify" required>
The URL path where the spam classifier will be accessible. This endpoint will receive POST requests with text content for classification.
</ParamField>

<ParamField body="spam_threshold" type="number" default="0.80" optional>
**Spam classification threshold (optional).** Probability threshold above which content is classified as spam. The default value of 0.80 works well for most use cases. Range: 0.0-1.0. Higher values = stricter detection, reducing false positives but may miss subtle spam. Lower values catch more spam but increase false positives.
</ParamField>

<ParamField body="laplace_smoothing_factor" type="number" default="1.0" optional>
**Laplace smoothing factor (optional).** Smoothing parameter for the Naive Bayes classifier that handles unseen tokens. The default value of 1.0 provides good balance for most content types. Range: 0.0+. Higher values provide more conservative classifications.
</ParamField>

<Note>
Configuration changes take effect immediately without requiring component redeployment. You can adjust these values based on your content patterns and false positive tolerance.
</Note>

## API Reference

### Request Parameters

<ParamField body="input" type="string" required>
The text content to classify for spam detection.
</ParamField>

### Example Request

```bash
curl -X POST https://yourdomain.com/classify \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, how are you today? I hope you are having a great day!"
  }'
```

### Response Fields

<ResponseField name="spam_probability" type="float">
Probability that the content is spam, ranging from 0.0 to 1.0. Values closer to 1.0 indicate higher likelihood of spam.
</ResponseField>

<ResponseField name="ham_probability" type="float">
Probability that the content is legitimate (ham), ranging from 0.0 to 1.0. Always equals 1.0 - spam_probability.
</ResponseField>

<ResponseField name="is_spam" type="boolean">
Boolean flag indicating whether the content exceeds the configured spam threshold. True if spam_probability >= spam_threshold.
</ResponseField>

<ResponseField name="confidence" type="float">
Classification confidence level, calculated as the absolute difference between spam and ham probabilities.
</ResponseField>

<ResponseField name="text" type="string">
The original input text that was classified, echoed back in the response.
</ResponseField>

### Example Response

```json
{
  "text": "Hello, how are you today? I hope you are having a great day!",
  "spam_probability": 0.23,
  "ham_probability": 0.77,
  "is_spam": false,
  "confidence": 0.54
}
```

## Usage Examples

<CodeGroup>
```javascript JavaScript/Node.js
const classifyText = async (text) => {
  try {
    const response = await fetch('/classify', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ input: text })
    });
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    const result = await response.json();
    
    if (result.is_spam) {
      console.log(`Spam detected with ${(result.spam_probability * 100).toFixed(1)}% confidence`);
    } else {
      console.log(`Content is legitimate with ${(result.confidence * 100).toFixed(1)}% confidence`);
    }
    
    return result;
  } catch (error) {
    console.error('Classification error:', error);
    throw error;
  }
};

// Example usage with different content types
await classifyText("Hello, how are you today?");
await classifyText("Buy now! Limited time offer! Click here for amazing deals!");
```

```python Python
import requests
import json

def classify_text(text, endpoint_url):
    """
    Classify text content using the Spam Classifier component
    
    Args:
        text (str): Text content to classify
        endpoint_url (str): Full URL to the spam classifier endpoint
    
    Returns:
        dict: Classification results with probabilities and confidence
    """
    try:
        response = requests.post(
            endpoint_url,
            headers={'Content-Type': 'application/json'},
            json={'input': text},
            timeout=10
        )
        
        response.raise_for_status()
        result = response.json()
        
        if result['is_spam']:
            print(f"Spam detected with {result['spam_probability']*100:.1f}% confidence")
        else:
            print(f"Content is legitimate with {result['confidence']*100:.1f}% confidence")
            
        return result
        
    except requests.exceptions.RequestException as e:
        print(f"Classification error: {e}")
        raise

# Example usage
classify_text("Hello, how are you today?", "https://yourdomain.com/classify")
classify_text("Buy now! Limited time offer!", "https://yourdomain.com/classify")
```

```bash cURL
# Basic spam classification request
curl -X POST https://yourdomain.com/classify \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Buy now! Limited time offer! Click here for amazing deals!"
  }'

# Legitimate content classification
curl -X POST https://yourdomain.com/classify \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, I hope you are having a wonderful day today!"
  }'

# Handle potential errors with verbose output
curl -X POST https://yourdomain.com/classify \
  -H "Content-Type: application/json" \
  -d '{"input": "Your message content here"}' \
  -w "HTTP Status: %{http_code}\nResponse Time: %{time_total}s\n" \
  -s
```
</CodeGroup>

### Form Validation Integration

```javascript
// Simple form validation with spam detection
document.getElementById('messageForm').addEventListener('submit', async (e) => {
  e.preventDefault();
  
  const messageInput = document.getElementById('messageInput');
  const message = messageInput.value;
  
  try {
    // Check for spam
    const response = await fetch('/classify', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ input: message })
    });
    
    const result = await response.json();
    
    if (result.is_spam) {
      alert(`Message appears to be spam (${(result.spam_probability * 100).toFixed(1)}% confidence)`);
      return;
    }
    
    // Submit the form if content is legitimate
    console.log('Message validated, submitting form');
    // Your form submission logic here
    
  } catch (error) {
    console.error('Validation error:', error);
    // Proceed with submission if spam check fails
  }
});
```

## Performance Characteristics

The Spam Classifier component delivers exceptional performance at the edge:

### Benchmark Results (x86, native)
- **Short text** (~5 words): ~28 µs processing time (72K tokens/sec)
- **Medium text** (~15 words): ~66 µs processing time (227K tokens/sec)
- **Long text** (~62 words): ~128 µs processing time (484K tokens/sec)

### Key Performance Features
- **O(log n) token lookup** using Finite State Transducers
- **64-bit packed counters** for memory efficiency
- **Log-space calculations** to prevent numerical overflow
- **Static model embedding** eliminates file I/O overhead
- **Sub-millisecond response times** for most content

## Technical Details

### Machine Learning Architecture

The component uses a sophisticated Naive Bayes implementation optimized for edge computing:

- **Text Processing Pipeline**: Advanced Unicode tokenization with multi-language support
- **Feature Engineering**: AlphaNumeric token filtering and text normalization
- **Classification Algorithm**: Naive Bayes with configurable Laplace smoothing
- **Performance Optimization**: FST-based token lookup and log-space probability calculations

### Text Processing Features

<Tabs>
<Tab title="Tokenization">
  Advanced Unicode-aware tokenization that handles:
  - Multi-language text processing
  - Special character normalization  
  - Stemming and lowercase conversion
  - Stop word filtering
</Tab>

<Tab title="Classification">
  Naive Bayes algorithm with:
  - Laplace smoothing for unseen tokens
  - Log-space probability calculations
  - Confidence score computation
  - Threshold-based binary classification
</Tab>

<Tab title="Optimization">
  Performance optimizations include:
  - O(log n) FST token lookup
  - 64-bit packed counter storage
  - Static model embedding in WASM
  - Zero-copy string processing
</Tab>
</Tabs>

## Use Cases

The Spam Classifier component is ideal for:

### Content Moderation
- **Comment Systems**: Filter spam comments on blogs and forums
- **User-Generated Content**: Moderate posts, reviews, and submissions
- **Social Media**: Detect spam in messages and posts

### Security Applications  
- **Form Protection**: Prevent spam submissions in contact forms
- **API Security**: Filter malicious content in API requests
- **Email Systems**: Pre-filter messages before processing

### Quality Control
- **Content Quality**: Ensure high-quality user contributions
- **Automated Triage**: Route suspicious content for human review
- **Compliance**: Meet anti-spam regulatory requirements

## Limitations and Considerations

<Warning>
This edge-optimized classifier prioritizes **speed and simplicity** over maximum accuracy. For applications requiring the highest precision spam detection, consider dedicated spam filtering services or more sophisticated machine learning solutions.
</Warning>

### Compared to Enterprise Solutions
- **Simpler feature set**: Uses basic Naive Bayes with token-based analysis
- **No behavioral analysis**: Lacks sender reputation, link analysis, or pattern recognition
- **Limited training data**: Smaller model size optimized for edge deployment
- **No real-time updates**: Model updates require component redeployment

### Best Fit Use Cases
This classifier works well for:
- **Basic content filtering** where speed is prioritized over perfect accuracy
- **First-line defense** in multi-layer spam protection strategies  
- **Edge computing scenarios** where low latency is critical
- **Privacy-focused applications** that avoid external API calls

<Note>
Consider combining this component with other security measures like rate limiting, CAPTCHA, or human moderation for comprehensive protection.
</Note>

## Error Handling

The component implements robust error handling with proper HTTP status codes:

### Status Codes
- `200 OK`: Successful classification with valid JSON input
- `400 Bad Request`: Invalid request body or malformed JSON
- `500 Internal Server Error`: Component processing error

### Error Response Format

When errors occur, the component returns a structured JSON error response:

```json
{
  "error": "Error message describing what went wrong"
}
```

## Best Practices

<Tip>
Start with a spam threshold of 0.80 and adjust based on your content patterns. Higher thresholds reduce false positives but may miss some spam.
</Tip>

<Warning>
The component processes text content only. Binary data, HTML tags, and special formatting are normalized during tokenization.
</Warning>

<Note>
For optimal performance, consider batching multiple short texts into single requests when processing large volumes of content.
</Note>

## Model Information

The embedded classification model is trained on diverse, multilingual datasets including:
- Email spam detection datasets
- Comment spam collections  
- Social media spam samples
- Multilingual content examples

The model supports incremental updates and can be retrained with domain-specific data for improved accuracy in specialized use cases.

## Related Components

<CardGroup cols={2}>
<Card title="DataDome Bot Protection" icon="shield" href="/components/security/datadome">
  Advanced bot detection and protection for comprehensive security coverage.
</Card>
</CardGroup>