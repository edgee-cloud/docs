---
title: OpenAI SDK
sidebarTitle: OpenAI SDK
description: Using Edgee with OpenAI SDK
icon: /images/icons/openai.svg
---

Edgee provides an **OpenAI-compatible API**, which means you can use the official OpenAI SDKs for TypeScript and Python with Edgee. This allows you to leverage Edgee's routing, observability, and cost tracking features without changing your existing code.

## Why Use OpenAI SDK with Edgee?

- **Up to 50% Cost Reduction**: Automatic token compression on every request
- **Real-Time Savings**: See exactly how many tokens and dollars you've saved
- **No Code Changes**: Use your existing OpenAI SDK code as-is
- **Multi-Provider Access**: Route to OpenAI, Anthropic, Google, and more through one API
- **Automatic Failover**: Built-in reliability with fallback providers
- **Cost Tracking**: Real-time visibility into token usage and costs
- **Observability**: Request tracing and logging across all providers

## Installation

Install the OpenAI SDK for your preferred language:

<Tabs>
  <Tab title="TypeScript">
    ```bash
    npm install openai
    ```
  </Tab>
  <Tab title="Python">
    ```bash
    pip install openai
    ```
  </Tab>
</Tabs>

## Configuration

Configure the OpenAI SDK to use Edgee's API endpoint:

<CodeGroup>

```typescript title="TypeScript"
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.edgee.ai/v1",
  apiKey: process.env.EDGEE_API_KEY, // Your Edgee API key
});

async function main() {
  const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [
      { role: "user", content: "What is the capital of France?" }
    ],
  });

  console.log(completion.choices[0].message.content);
}

main();
```

```python title="Python"
from openai import OpenAI
from os import getenv

# Configure OpenAI SDK to use Edgee
client = OpenAI(
  base_url="https://api.edgee.ai/v1",
  api_key=getenv("EDGEE_API_KEY"),  # Your Edgee API key
)

completion = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "user",
      "content": "What is the capital of France?",
    },
  ],
)

print(completion.choices[0].message.content)
```

</CodeGroup>

## Cost Tracking & Compression

Every response includes token compression and cost metrics through the standard OpenAI `usage` field:

<CodeGroup>

```typescript title="TypeScript"
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.edgee.ai/v1",
  apiKey: process.env.EDGEE_API_KEY,
});

const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [
    { role: "user", content: "Summarize this long document..." }
  ],
});

console.log(completion.choices[0].message.content);

// Access compression metrics (if compression was applied)
if (completion.compression) {
  console.log(`Tokens saved: ${completion.compression.saved_tokens}`);
  console.log(`Compression rate: ${(completion.compression.rate * 100).toFixed(1)}%`);
}
console.log(`Total tokens: ${completion.usage.total_tokens}`);
```

```python title="Python"
from openai import OpenAI
from os import getenv

client = OpenAI(
  base_url="https://api.edgee.ai/v1",
  api_key=getenv("EDGEE_API_KEY"),
)

completion = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {"role": "user", "content": "Summarize this long document..."}
  ],
)

print(completion.choices[0].message.content)

# Access compression metrics (if compression was applied)
if hasattr(completion, 'compression') and completion.compression:
    print(f"Tokens saved: {completion.compression.saved_tokens}")
    print(f"Compression rate: {completion.compression.rate * 100:.1f}%")
print(f"Total tokens: {completion.usage.total_tokens}")
```

</CodeGroup>

<Note>
  Edgee extends the OpenAI API response with a `compression` field containing compression metrics (`input_tokens`, `saved_tokens`, `rate`). All standard OpenAI fields remain unchanged.
</Note>

## Advanced Usage

### Function Calling (Tools)

Edgee fully supports OpenAI's function calling interface:

<CodeGroup>

```typescript title="TypeScript"
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.edgee.ai/v1",
  apiKey: process.env.EDGEE_API_KEY,
});

async function main() {
  const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [
      { role: "user", content: "What's the weather in Paris?" }
    ],
    tools: [
      {
        type: "function",
        function: {
          name: "get_weather",
          description: "Get the current weather for a location",
          parameters: {
            type: "object",
            properties: {
              location: {
                type: "string",
                description: "City name",
              },
            },
            required: ["location"],
          },
        },
      },
    ],
    tool_choice: "auto",
  });

  if (completion.choices[0].message.tool_calls) {
    console.log("Tool calls:", completion.choices[0].message.tool_calls);
  } else {
    console.log("Response:", completion.choices[0].message.content);
  }
}

main();
```

```python title="Python"
from openai import OpenAI
from os import getenv

client = OpenAI(
  base_url="https://api.edgee.ai/v1",
  api_key=getenv("EDGEE_API_KEY"),
)

completion = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "user",
      "content": "What's the weather in Paris?",
    },
  ],
  tools=[
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get the current weather for a location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "City name",
            },
          },
          "required": ["location"],
        },
      },
    },
  ],
  tool_choice="auto",
)

if completion.choices[0].message.tool_calls:
    print("Tool calls:", completion.choices[0].message.tool_calls)
else:
    print("Response:", completion.choices[0].message.content)
```

</CodeGroup>

### Tags

You can add tags to your requests for analytics and filtering using the `x-edgee-tags` header:

<CodeGroup>

```typescript title="TypeScript"
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.edgee.ai/v1",
  apiKey: process.env.EDGEE_API_KEY,
  defaultHeaders: {
    "x-edgee-tags": "production,user-123,summarization",
  },
});

// All requests will include these tags
const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [
    { role: "user", content: "What is the capital of France?" }
  ],
});
```

```python title="Python"
from openai import OpenAI
from os import getenv

# Tags applied to all requests via default headers
client = OpenAI(
    base_url="https://api.edgee.ai/v1",
    api_key=getenv("EDGEE_API_KEY"),
    default_headers={
        "x-edgee-tags": "production,user-123,summarization",
    },
)

# Or per-request using extra_headers
completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "user", "content": "What is the capital of France?"},
    ],
    extra_headers={
        "x-edgee-tags": "one-off-tag,experiment",
    },
)
```

</CodeGroup>

<Tip>
  Tags are comma-separated strings in the header. They help you categorize and filter requests in Edgee's analytics dashboard.
</Tip>

### Streaming Responses

Edgee supports streaming responses for real-time token delivery:

<CodeGroup>

```typescript title="TypeScript"
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.edgee.ai/v1",
  apiKey: process.env.EDGEE_API_KEY,
});

async function main() {
  const stream = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [
      { role: "user", content: "Tell me a short story" }
    ],
    stream: true,
  });

  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || "";
    process.stdout.write(content);
  }
}

main();
```

```python title="Python"
from openai import OpenAI
from os import getenv

client = OpenAI(
  base_url="https://api.edgee.ai/v1",
  api_key=getenv("EDGEE_API_KEY"),
)

stream = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "user",
      "content": "Tell me a short story",
    },
  ],
  stream=True,
)

for chunk in stream:
    content = chunk.choices[0].delta.content or ""
    print(content, end="", flush=True)
```

</CodeGroup>


## Migration from OpenAI

If you're already using the OpenAI SDK, migrating to Edgee is straightforward:

1. **Change the base URL**: Update `baseURL` from `https://api.openai.com/v1` to `https://api.edgee.ai/v1`
2. **Update API key**: Use your Edgee API key instead of your OpenAI key
3. **That's it!** Your existing code will work without any other changes

<Tip>
  All OpenAI SDK features are supported, including streaming, function calling, and response formatting. Edgee maintains full compatibility with the OpenAI API specification.
</Tip>

## What's Next?

<CardGroup cols={2}>
  <Card title="Get API Key" icon="key" href="/quickstart/api-key">
    Create an account and get your Edgee API key to start using the OpenAI SDK.
  </Card>
  <Card title="Supported Models" icon="brain" href="https://www.edgee.ai/models">
    Browse 200+ models available through Edgee from multiple providers.
  </Card>
  <Card title="Edgee SDK" icon="code" href="/sdk/typescript">
    Check out the native Edgee SDKs for TypeScript, Python, Go, and Rust.
  </Card>
  <Card title="API Reference" icon="terminal" href="/api-reference">
    Explore the full REST API documentation.
  </Card>
</CardGroup>