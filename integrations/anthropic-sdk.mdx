---
title: Anthropic SDK
description: Use Edgee with the Anthropic SDK for building AI applications with Claude models.
icon: /images/icons/anthropic.svg
---

The Anthropic SDK provides official Python and TypeScript clients for interacting with Claude models. Edgee's OpenAI-compatible API works seamlessly with the Anthropic SDK, allowing you to leverage the SDK's features while gaining access to Edgee's **up to 50% cost reduction** through token compression, unified gateway, automatic failover, and full observability.

## Installation

<Tabs>
  <Tab title="Python">
    ```bash
    pip install anthropic
    ```
  </Tab>
  <Tab title="TypeScript">
    ```bash
    npm install @anthropic-ai/sdk
    ```
  </Tab>
</Tabs>

## Basic Usage

<Tabs>
  <Tab title="Python">
    ```python
    import os
    from anthropic import Anthropic

    # Initialize client with Edgee endpoint
    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
    )

    # Send a message
    message = client.messages.create(
        model="claude-sonnet-4.5",
        max_tokens=1024,
        messages=[
            {"role": "user", "content": "What is the capital of France?"}
        ]
    )

    print(message.content)

    # Access token usage
    print(f"Input tokens: {message.usage.input_tokens}")
    print(f"Output tokens: {message.usage.output_tokens}")
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    // Initialize client with Edgee endpoint
    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
    });

    // Send a message
    const message = await client.messages.create({
      model: 'claude-sonnet-4.5',
      max_tokens: 1024,
      messages: [
        { role: 'user', content: 'What is the capital of France?' }
      ]
    });

    console.log(message.content);

    // Access token usage
    console.log(`Input tokens: ${message.usage.input_tokens}`);
    console.log(`Output tokens: ${message.usage.output_tokens}`);
    ```
  </Tab>
</Tabs>

## Streaming Responses

Stream responses for real-time token delivery:

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
    )

    # Stream messages
    with client.messages.stream(
        model="claude-sonnet-4.5",
        max_tokens=1024,
        messages=[
            {"role": "user", "content": "Write a short poem about coding"}
        ]
    ) as stream:
        for text in stream.text_stream:
            print(text, end="", flush=True)
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
    });

    // Stream messages
    const stream = await client.messages.create({
      model: 'claude-sonnet-4.5',
      max_tokens: 1024,
      messages: [
        { role: 'user', content: 'Write a short poem about coding' }
      ],
      stream: true,
    });

    for await (const event of stream) {
      if (event.type === 'content_block_delta'
          && event.delta.type === 'text_delta') {
        process.stdout.write(event.delta.text);
      }
    }
    ```
  </Tab>
</Tabs>

## Token Usage Tracking

Access standard Anthropic token usage metrics in every response:

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
    )

    message = client.messages.create(
        model="claude-sonnet-4.5",
        max_tokens=1024,
        messages=[{"role": "user", "content": "Analyze this long document..."}]
    )

    print(message.content)
    print(f"Input tokens: {message.usage.input_tokens}")
    print(f"Output tokens: {message.usage.output_tokens}")
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
    });

    const message = await client.messages.create({
      model: 'claude-sonnet-4.5',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Analyze this long document...' }]
    });

    console.log(message.content);
    console.log(`Input tokens: ${message.usage.input_tokens}`);
    console.log(`Output tokens: ${message.usage.output_tokens}`);
    ```
  </Tab>
</Tabs>

<Note>
  When compression is enabled, `input_tokens` reflects the compressed token count. View detailed compression metrics in the [Edgee dashboard](/features/observability).
</Note>

## Compression & Tags via Headers

When using the Anthropic SDK with Edgee, you can control token compression and add tags using HTTP headers:

### Enabling Compression

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
        default_headers={
            "x-edgee-enable-compression": "true",
            "x-edgee-compression-rate": "0.8",  # Target 80% compression (0.0-1.0)
        }
    )

    # All requests will use compression with 80% target rate
    message = client.messages.create(
        model="claude-sonnet-4.5",
        max_tokens=1024,
        messages=[{"role": "user", "content": "Analyze this document..."}]
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
      defaultHeaders: {
        'x-edgee-enable-compression': 'true',
        'x-edgee-compression-rate': '0.8',  // Target 80% compression (0.0-1.0)
      }
    });

    // All requests will use compression
    const message = await client.messages.create({
      model: 'claude-sonnet-4.5',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Analyze this document...' }]
    });
    ```
  </Tab>
</Tabs>

### Adding Tags for Analytics

Combine compression with tags to track requests in your dashboard:

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
        default_headers={
            "x-edgee-enable-compression": "true",
            "x-edgee-compression-rate": "0.8",
            "x-edgee-tags": "production,anthropic-sdk,user-123"
        }
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
      defaultHeaders: {
        'x-edgee-enable-compression': 'true',
        'x-edgee-compression-rate': '0.8',
        'x-edgee-tags': 'production,anthropic-sdk,user-123'
      }
    });
    ```
  </Tab>
</Tabs>

**Available Headers:**

| Header | Type | Description |
|--------|------|-------------|
| `x-edgee-enable-compression` | `"true"` or `"false"` | Enable token compression for requests (overrides console settings) |
| `x-edgee-compression-rate` | `string` | Target compression rate (0.0-1.0, default 0.75) |
| `x-edgee-tags` | `string` | Comma-separated tags for analytics and filtering |

<Tip>
  You can also enable compression organization-wide or per API key in the [Edgee console](/features/token-compression#enabling-token-compression). Headers override console settings for specific requests.
</Tip>

## Multi-Provider Access

With Edgee, you can access models from multiple providers using the same Anthropic SDK client and compare costs across providers:

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
    )

    # Use Claude
    claude_response = client.messages.create(
        model="claude-sonnet-4.5",
        max_tokens=1024,
        messages=[{"role": "user", "content": "Hello!"}]
    )

    # Use GPT-4 through the same client
    gpt_response = client.messages.create(
        model="gpt-4o",
        max_tokens=1024,
        messages=[{"role": "user", "content": "Hello!"}]
    )

    # Use Mistral
    mistral_response = client.messages.create(
        model="mistral-large",
        max_tokens=1024,
        messages=[{"role": "user", "content": "Hello!"}]
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai/',
      apiKey: process.env.EDGEE_API_KEY,
    });

    // Use Claude
    const claudeResponse = await client.messages.create({
      model: 'claude-sonnet-4.5',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Hello!' }]
    });

    // Use GPT-4 through the same client
    const gptResponse = await client.messages.create({
      model: 'gpt-4o',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Hello!' }]
    });

    // Use Mistral
    const mistralResponse = await client.messages.create({
      model: 'mistral-large',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Hello!' }]
    });
    ```
  </Tab>
</Tabs>

## Function Calling (Tools)

Use Claude's tool calling with Edgee:

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
    )

    # Define a tool
    tools = [
        {
            "name": "get_weather",
            "description": "Get the current weather in a given location",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                    }
                },
                "required": ["location"]
            }
        }
    ]

    # Send message with tools
    message = client.messages.create(
        model="claude-sonnet-4.5",
        max_tokens=1024,
        tools=tools,
        messages=[
            {"role": "user", "content": "What's the weather like in Paris?"}
        ]
    )

    print(message.content)
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
    });

    // Define a tool
    const tools = [
      {
        name: 'get_weather',
        description: 'Get the current weather in a given location',
        input_schema: {
          type: 'object',
          properties: {
            location: {
              type: 'string',
              description: 'The city and state, e.g. San Francisco, CA'
            }
          },
          required: ['location']
        }
      }
    ];

    // Send message with tools
    const message = await client.messages.create({
      model: 'claude-sonnet-4.5',
      max_tokens: 1024,
      tools: tools,
      messages: [
        { role: 'user', content: "What's the weather like in Paris?" }
      ]
    });

    console.log(message.content);
    ```
  </Tab>
</Tabs>

## Error Handling and Retries

The Anthropic SDK includes built-in retry logic, which works seamlessly with Edgee's automatic failover:

<Tabs>
  <Tab title="Python">
    ```python
    from anthropic import Anthropic, APIError

    client = Anthropic(
        base_url="https://api.edgee.ai",
        api_key=os.environ.get("EDGEE_API_KEY"),
        max_retries=3,  # SDK will retry up to 3 times
    )

    try:
        message = client.messages.create(
            model="claude-sonnet-4.5",
            max_tokens=1024,
            messages=[{"role": "user", "content": "Hello!"}]
        )
        print(message.content)
    except APIError as e:
        print(f"API Error: {e}")
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';

    const client = new Anthropic({
      baseURL: 'https://api.edgee.ai',
      apiKey: process.env.EDGEE_API_KEY,
      maxRetries: 3,  // SDK will retry up to 3 times
    });

    try {
      const message = await client.messages.create({
        model: 'claude-sonnet-4.5',
        max_tokens: 1024,
        messages: [{ role: 'user', content: 'Hello!' }]
      });
      console.log(message.content);
    } catch (error) {
      console.error('API Error:', error);
    }
    ```
  </Tab>
</Tabs>

## Authentication

Edgee uses standard Bearer token authentication. Set your API key as an environment variable:

```bash
export EDGEE_API_KEY="sk-edgee-..."
```

Or in your `.env` file:

```bash
EDGEE_API_KEY=sk-edgee-...
```

The SDK automatically formats the authentication header as:
```
Authorization: Bearer {api_key}
```

## Benefits of Using Anthropic SDK with Edgee

<CardGroup cols={2}>
  <Card title="Up to 50% Cost Reduction" icon="dollar-sign">
    Automatic token compression on every request reduces input tokens by up to 50% while preserving output quality.
  </Card>

  <Card title="Multi-Provider Cost Comparison" icon="chart-mixed">
    Compare costs across Claude, GPT-4, Mistral, and 200+ models. Track compression savings per provider.
  </Card>

  <Card title="Automatic Failover" icon="shield-check">
    If Claude is rate-limited or unavailable, Edgee automatically routes to backup models without code changes.
  </Card>

  <Card title="Full Observability" icon="chart-line">
    Monitor latency, token usage, compression ratios, error rates, and costs for all requests in one dashboard.
  </Card>
</CardGroup>

## Complete Example

Here's a complete application example:

<Tabs>
  <Tab title="Python">
    ```python
    #!/usr/bin/env python3
    import os
    from anthropic import Anthropic

    def main():
        # Initialize client
        client = Anthropic(
            base_url="https://api.edgee.ai",
            api_key=os.environ.get("EDGEE_API_KEY"),
            default_headers={
                "x-edgee-tags": "production,chat-app"
            }
        )

        # Chat loop
        conversation = []
        print("Chat with Claude (type 'quit' to exit)")

        while True:
            user_input = input("\nYou: ")
            if user_input.lower() == 'quit':
                break

            conversation.append({
                "role": "user",
                "content": user_input
            })

            # Stream response
            print("\nClaude: ", end="", flush=True)
            with client.messages.stream(
                model="claude-sonnet-4.5",
                max_tokens=1024,
                messages=conversation
            ) as stream:
                assistant_message = ""
                for text in stream.text_stream:
                    print(text, end="", flush=True)
                    assistant_message += text

            conversation.append({
                "role": "assistant",
                "content": assistant_message
            })

    if __name__ == "__main__":
        main()
    ```
  </Tab>

  <Tab title="TypeScript">
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';
    import * as readline from 'readline';

    async function main() {
      // Initialize client
      const client = new Anthropic({
        baseURL: 'https://api.edgee.ai',
        apiKey: process.env.EDGEE_API_KEY,
        defaultHeaders: {
          'x-edgee-tags': 'production,chat-app'
        }
      });

      const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout
      });

      const conversation: Array<{ role: string; content: string }> = [];

      console.log("Chat with Claude (type 'quit' to exit)");

      const chat = () => {
        rl.question('\nYou: ', async (input) => {
          if (input.toLowerCase() === 'quit') {
            rl.close();
            return;
          }

          conversation.push({
            role: 'user',
            content: input
          });

          process.stdout.write('\nClaude: ');

          const stream = await client.messages.create({
            model: 'claude-sonnet-4.5',
            max_tokens: 1024,
            messages: conversation,
            stream: true,
          });

          let assistantMessage = '';
          for await (const event of stream) {
            if (event.type === 'content_block_delta'
                && event.delta.type === 'text_delta') {
              process.stdout.write(event.delta.text);
              assistantMessage += event.delta.text;
            }
          }

          conversation.push({
            role: 'assistant',
            content: assistantMessage
          });

          chat();
        });
      };

      chat();
    }

    main();
    ```
  </Tab>
</Tabs>

## Next Steps

- Explore [Anthropic SDK documentation](https://docs.anthropic.com/claude/reference/getting-started-with-the-api) for advanced features
- Check out [Edgee's routing capabilities](/features/automatic-model-selection) for intelligent model selection
- Set up [observability](/features/observability) to monitor your applications
- Configure [privacy controls](/features/privacy) to manage data retention
