---
title: Welcome to Edgee
description: The AI Gateway that TL;DR tokens.
icon: house
mode: "center"
---

Edgee is an **AI Gateway** that reduces LLM costs by up to 50% through intelligent token compression. Behind a single OpenAI-compatible API, you get access to 200+ models with automatic cost optimization, intelligent routing, and full observability.

## Get Started in 6 Lines

<Tabs>
  <Tab title="TypeScript">    
    ```typescript
    import Edgee from 'edgee';
    
    const edgee = new Edgee("your-api-key");
    
    const response = await edgee.send({
      model: 'gpt-4o',
      input: 'What is the capital of France?',
    });

    console.log(response.text);
    if (response.compression) {
      console.log(`Tokens saved: ${response.compression.saved_tokens}`);
    }
    ```
  </Tab>
  
  <Tab title="Python">    
    ```python
    from edgee import Edgee
    
    edgee = Edgee("your-api-key")
    
    response = edgee.send(
        model="gpt-4o",
        input="What is the capital of France?"
    )
    
    print(response.text)
    if response.compression:
        print(f"Tokens saved: {response.compression.saved_tokens}")
    ```
  </Tab>
  
  <Tab title="Go">    
    ```go
    package main

    import (
        "fmt"
        "log"
        "github.com/edgee-cloud/go-sdk/edgee"
    )

    func main() {
        client, _ := edgee.NewClient("your-api-key")

        response, err := client.Send("gpt-4o", "What is the capital of France?")
        if err != nil {
            log.Fatal(err)
        }

        fmt.Println(response.Text())
        if response.Compression != nil {
            fmt.Printf("Tokens saved: %d\n", response.Compression.SavedTokens)
        }
    }
    ```
  </Tab>
  
  <Tab title="Rust">
    ```rust
    use edgee::Edgee;

    let client = Edgee::with_api_key("your-api-key");
    let response = client.send("gpt-4o", "What is the capital of France?").await.unwrap();

    println!("{}", response.text().unwrap_or(""));
    if let Some(compression) = &response.compression {
        println!("Tokens saved: {}", compression.saved_tokens);
    }
    ```
  </Tab>
</Tabs>

That's it. You now have access to every major LLM provider, automatic failovers, cost tracking, and full observability, all through one simple API.



<img className="block dark:hidden" src="/images/ai-gateway-horizontal-light.jpg" alt="Edgee AI Gateway"/>
<img className="hidden dark:block" src="/images/ai-gateway-horizontal-dark.jpg" alt="Edgee AI Gateway"/>

<CardGroup cols={3}>
    <Card title="3B+ Requests/Month" icon="chart-line" iconType="duotone" />
    <Card title="Up to 50% Input Token Reduction" icon="dollar-sign" iconType="duotone" />
    <Card title="100+ Global PoPs" icon="globe" iconType="duotone" />
</CardGroup>

## Why Choose Edgee?

Building with LLMs is powerful, but comes with challenges:

- **Exploding AI costs**: Token usage adds up fast with RAG, long contexts, and multi-turn conversations
- **Cost opacity**: Bills spike with no visibility into what's driving costs
- **Vendor lock-in**: Your code is tightly coupled to a single provider's API
- **No fallbacks**: When OpenAI goes down, your app goes down
- **Security concerns**: Sensitive data flows directly to third-party providers
- **Fragmented observability**: Logs scattered across multiple dashboards

**Edgee solves all of this with a single integration.**


## Core Capabilities

<CardGroup cols={2}>
  <Card title="Token Compression" icon="dollar-sign" iconType="duotone" href="/features/token-compression">
    Reduce prompt size by up to 50% without losing intent.
    Ideal for RAG, long contexts, and multi-turn agents.
  </Card>

  <Card title="Unified API" icon="plug" iconType="duotone" href="/quickstart">
    One SDK, access to 200+ models from OpenAI, Anthropic, Google, Mistral, and more.
    Switch providers with a single line change.
  </Card>

  <Card title="Intelligent Routing" icon="route" iconType="duotone" href="/features/automatic-model-selection">
    Automatic failover, load balancing, and smart model selection.
    Optimize for cost, performance, or both.
  </Card>

  <Card title="Cost & Observability" icon="chart-line" iconType="duotone" href="/features/observability">
    Real-time cost tracking, latency metrics, and request logs.
    Know exactly what your AI is doing and costing.
  </Card>

  <Card title="Privacy Controls" icon="shield" iconType="duotone" href="/features/privacy">
    Control how your data flows with configurable logging and retention.
    Enable provider-side ZDR where available, and apply privacy layers to prompts.
  </Card>
</CardGroup>
